{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Driving - Car Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:11:37.185164Z",
     "start_time": "2024-05-15T12:11:37.183703Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yad2k.utils.utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08f29f6200340f3ea6223aece625671b",
     "grade": false,
     "grade_id": "cell-125a819999f836d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-15T12:12:53.069101Z",
     "start_time": "2024-05-15T12:12:53.057945Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.6):\n",
    "    x = 10\n",
    "    y = tf.constant(100)\n",
    "    box_scores = box_class_probs*box_confidence\n",
    "    box_classes = tf.math.argmax(box_scores,axis=-1)\n",
    "    box_class_scores = tf.math.reduce_max(box_scores,axis=-1)\n",
    "    filtering_mask = (box_class_scores >= threshold)\n",
    "    scores = tf.boolean_mask(box_class_scores,filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes,filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes,filtering_mask)\n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "615c94cc11aa6ce681b0ee798e137364",
     "grade": true,
     "grade_id": "cell-b1c9aaf8e3305fee",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-15T12:12:54.303990Z",
     "start_time": "2024-05-15T12:12:54.234939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 9.270486\n",
      "boxes[2] = [ 4.6399336  3.2303846  4.431282  -2.202031 ]\n",
      "classes[2] = 8\n",
      "scores.shape = (1789,)\n",
      "boxes.shape = (1789, 4)\n",
      "classes.shape = (1789,)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(10)\n",
    "box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "box_class_probs = tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.5)\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.shape))\n",
    "print(\"boxes.shape = \" + str(boxes.shape))\n",
    "print(\"classes.shape = \" + str(classes.shape))\n",
    "\n",
    "assert type(scores) == EagerTensor, \"Using tensorflow functions\"\n",
    "assert type(boxes) == EagerTensor, \"Using tensorflow functions\"\n",
    "assert type(classes) == EagerTensor, \"Using tensorflow functions\"\n",
    "\n",
    "assert scores.shape == (1789,), \"Wrong shape in scores\"\n",
    "assert boxes.shape == (1789, 4), \"Wrong shape in boxes\"\n",
    "assert classes.shape == (1789,), \"Wrong shape in classes\"\n",
    "\n",
    "assert np.isclose(scores[2].numpy(), 9.270486), \"Values are wrong on scores\"\n",
    "assert np.allclose(boxes[2].numpy(), [4.6399336, 3.2303846, 4.431282, -2.202031]), \"Values are wrong on boxes\"\n",
    "assert classes[2].numpy() == 8, \"Values are wrong on classes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Non-max suppression uses the very important function called **\"Intersection over Union\"**, or IoU.\n",
    "<img src=\"nb_images/iou.png\" style=\"width:500px;height:400;\">\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15fb8b9d060ca2737fc7495a4fefe342",
     "grade": false,
     "grade_id": "cell-43008d769892f26f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-15T12:17:39.708803Z",
     "start_time": "2024-05-15T12:17:39.705482Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "    xi1 = max(box1_x1,box2_x1)\n",
    "    yi1 = max(box1_y1,box2_y1)\n",
    "    xi2 = min(box1_x2,box2_x2)\n",
    "    yi2 = min(box1_y2,box2_y2)\n",
    "    inter_width = max(0,yi2 - yi1)\n",
    "    inter_height = max(0,xi2 - xi1)\n",
    "    inter_area = inter_width*inter_height\n",
    "    box1_area = (box1_x2-box1_x1)*((box1_y2-box1_y1))\n",
    "    box2_area = (box2_x2-box2_x1)*((box2_y2-box2_y1))\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area/union_area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b46fc75134940f8dc2b63be892a5342",
     "grade": false,
     "grade_id": "cell-45dde3252e543bbd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-15T12:17:40.199634Z",
     "start_time": "2024-05-15T12:17:40.193477Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes_tensor,iou_threshold)\n",
    "    scores = tf.gather(scores,nms_indices)\n",
    "    boxes = tf.gather(boxes,nms_indices)\n",
    "    classes = tf.gather(classes,nms_indices)\n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:17:40.695863Z",
     "start_time": "2024-05-15T12:17:40.692140Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "    return tf.keras.backend.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b86b734e67da53186508d3e73aa5e413",
     "grade": false,
     "grade_id": "cell-baa7fe688d21f2dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-15T12:18:07.539671Z",
     "start_time": "2024-05-15T12:18:07.536481Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, score_threshold)\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:17:44.093991Z",
     "start_time": "2024-05-15T12:17:44.033045Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'version https://git-lfs.github.com/spec/v1\\n'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m class_names \u001B[38;5;241m=\u001B[39m read_classes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_data/coco_classes.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m anchors \u001B[38;5;241m=\u001B[39m \u001B[43mread_anchors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_data/yolo_anchors.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m model_image_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m608\u001B[39m, \u001B[38;5;241m608\u001B[39m) \u001B[38;5;66;03m# Same as yolo_model input layer size\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/DL/C4 - Convolutional Neural Networks/Week 3/Car detection for Autonomous Driving/yad2k/utils/utils.py:41\u001B[0m, in \u001B[0;36mread_anchors\u001B[0;34m(anchors_path)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(anchors_path) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     40\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreadline()\n\u001B[0;32m---> 41\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43manchors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     42\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(anchors)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m anchors\n",
      "File \u001B[0;32m~/Desktop/DL/C4 - Convolutional Neural Networks/Week 3/Car detection for Autonomous Driving/yad2k/utils/utils.py:41\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(anchors_path) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     40\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreadline()\n\u001B[0;32m---> 41\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m anchors\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m     42\u001B[0m     anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(anchors)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m anchors\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'version https://git-lfs.github.com/spec/v1\\n'"
     ]
    }
   ],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "model_image_size = (608, 608) # Same as yolo_model input layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:18:55.386404Z",
     "start_time": "2024-05-15T12:18:53.106407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "ename": "OpError",
     "evalue": "model_data/variables/variables.data-00000-of-00001; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m yolo_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_data/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/env1/lib/python3.11/site-packages/keras/saving/saving_api.py:212\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    205\u001B[0m         filepath,\n\u001B[1;32m    206\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    207\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    208\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    209\u001B[0m     )\n\u001B[1;32m    211\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/env1/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/envs/env1/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py:45\u001B[0m, in \u001B[0;36merror_translator\u001B[0;34m(e)\u001B[0m\n\u001B[1;32m     43\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mInternalError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, error_message)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 45\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors_impl\u001B[38;5;241m.\u001B[39mOpError(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, error_message, errors_impl\u001B[38;5;241m.\u001B[39mUNKNOWN)\n",
      "\u001B[0;31mOpError\u001B[0m: model_data/variables/variables.data-00000-of-00001; No such file or directory"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"model_data/\", compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the weights of a trained YOLO model. Here's a summary of the layers your model contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:17:30.846712Z",
     "start_time": "2024-05-15T12:17:30.802383Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43myolo_model\u001B[49m\u001B[38;5;241m.\u001B[39msummary()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'yolo_model' is not defined"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:22:14.300492Z",
     "start_time": "2024-05-15T12:22:14.207012Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(image_file):\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "    \n",
    "    yolo_model_outputs = yolo_model(image_data)\n",
    "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
    "    \n",
    "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, 0.3, 0.5)\n",
    "\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), \"images/\" + image_file))\n",
    "\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    \n",
    "    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n",
    "    \n",
    "    image.save(os.path.join(\"out\", str(image_file).split('.')[0]+\"_annotated.\" +str(image_file).split('.')[1] ), quality=100)\n",
    "    \n",
    "    output_image = Image.open(os.path.join(\"out\", str(image_file).split('.')[0]+\"_annotated.\" +str(image_file).split('.')[1] ))\n",
    "    imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:22:22.240913Z",
     "start_time": "2024-05-15T12:22:22.098664Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m out_scores, out_boxes, out_classes \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m0001.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 4\u001B[0m, in \u001B[0;36mpredict\u001B[0;34m(image_file)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(image_file):\n\u001B[1;32m      2\u001B[0m     image, image_data \u001B[38;5;241m=\u001B[39m preprocess_image(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m image_file, model_image_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m608\u001B[39m, \u001B[38;5;241m608\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m     yolo_model_outputs \u001B[38;5;241m=\u001B[39m \u001B[43myolo_model\u001B[49m(image_data)\n\u001B[1;32m      5\u001B[0m     yolo_outputs \u001B[38;5;241m=\u001B[39m yolo_head(yolo_model_outputs, anchors, \u001B[38;5;28mlen\u001B[39m(class_names))\n\u001B[1;32m      7\u001B[0m     out_scores, out_boxes, out_classes \u001B[38;5;241m=\u001B[39m yolo_eval(yolo_outputs, [image\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m1\u001B[39m],  image\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m0\u001B[39m]], \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m0.5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'yolo_model' is not defined"
     ]
    }
   ],
   "source": [
    "out_scores, out_boxes, out_classes = predict(\"0001.jpg\")"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
